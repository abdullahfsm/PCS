{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac6d29-ec02-44a2-b64c-8054c9a5eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "sys.path.append('plotting_utils')\n",
    "from plotting_utils.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e3433-d646-4e23-b75f-8a68d8cd9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace=\"gavel\"\n",
    "file_dir = \"new_data\"\n",
    "fname = \"{}_gavel_result.csv\"\n",
    "pd_data = {}\n",
    "min_avg_jct = float('inf')\n",
    "all_policies = [\"AFS\", \"SRSF\", \"THEMIS\", \"PCS_jct\", \"PCS_bal\", \"PCS_pred\", \"FIFO\"] \n",
    "for policy in all_policies:\n",
    "    file_path = os.path.join(file_dir, f\"{policy}_{trace}_result.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['jct'] =  df['end_time'] - df['submit_time']\n",
    "    df['pred_jct'] =  df['estimated_end_time'] - df['submit_time']\n",
    "    df['error'] = 100.0 * (df['pred_jct'] - df['jct']).abs() / df['pred_jct']\n",
    "    min_avg_jct = df['jct'].mean() if min_avg_jct > df['jct'].mean() else min_avg_jct\n",
    "    pd_data[policy] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43acfe86-f432-4d6c-8cfc-1c03554e1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our data in the format that plotting_utils understands\n",
    "# Fig8a\n",
    "policies = [\"AFS\", \"SRSF\", \"THEMIS\", \"PCS_jct\"]\n",
    "labels = dict(zip(policies, [\"afs\", \"tiresias\", \"themis\", \"flex_jct\"]))\n",
    "data = {}\n",
    "for policy in policies:\n",
    "    data[labels[policy]] = [pd_data[policy]['error'].mean(), pd_data[policy]['error'].quantile(0.99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ebd47-9d8f-400c-923f-c29d0c4b71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_fig8a(data=data)\n",
    "ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0dfce-a403-4c6a-a4e9-dfefab1f95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our data in the format that plotting_utils understands\n",
    "# Fig8b\n",
    "policies = [\"AFS\", \"SRSF\", \"THEMIS\", \"FIFO\", \"PCS_pred\" , \"PCS_jct\", \"PCS_bal\"]\n",
    "data = {}\n",
    "for policy in policies:\n",
    "    data[policy] = {\"p99_err_pred\": pd_data[policy]['error'].quantile(0.99),\n",
    "                    \"normalized_mean_jct\": pd_data[policy]['jct'].mean()/min_avg_jct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11658d-f2ff-4c0a-9aca-103b36232b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_fig8b(data=data)\n",
    "ax.figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
