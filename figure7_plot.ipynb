{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1068a31-4728-43b4-8a2f-4fe671945a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "sys.path.append('plotting_utils')\n",
    "from plotting_utils.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367ff59-71b5-4d86-abcd-0a7b6f2b8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection data from csv files\n",
    "file_dir = \"new_data\"\n",
    "fname = \"{}_{}_result.csv\"\n",
    "pd_data = {}\n",
    "\n",
    "# all_traces = [\"0e4a51\",\"6214e9\",\"6c71a0\",\"b436b2\",\"ee9e8c\"]\n",
    "all_traces = [\"ee9e8c\"]\n",
    "all_policies = [\"AFS\", \"SRSF\", \"THEMIS\", \"PCS_jct\", \"PCS_bal\", \"PCS_pred\", \"FIFO\"] \n",
    "\n",
    "for trace in all_traces:\n",
    "    pd_data[trace] = {}\n",
    "    min_avg_jct = float('inf')\n",
    "    for policy in all_policies:\n",
    "        file_path = os.path.join(file_dir, f\"{policy}_{trace}_result.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['jct'] =  df['end_time'] - df['submit_time']\n",
    "            df['pred_jct'] =  df['estimated_end_time'] - df['submit_time']\n",
    "            df['error'] = 100.0 * (df['pred_jct'] - df['jct']).abs() / df['pred_jct']\n",
    "            min_avg_jct = df['jct'].mean() if min_avg_jct > df['jct'].mean() else min_avg_jct\n",
    "            pd_data[trace][policy] = df\n",
    "    pd_data[trace][\"min_avg_jct\"] = min_avg_jct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f3372-c514-4403-90a1-1bea788b70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming pd_data is a two-level dictionary with traces as keys and policies as keys of the inner dictionary,\n",
    "# and each inner dictionary also contains a 'min_avg_jct' key\n",
    "\n",
    "# Create a list of DataFrames and a list of custom keys\n",
    "dfs = []\n",
    "custom_keys = []\n",
    "\n",
    "# Iterate over traces\n",
    "for trace, policies_dict in pd_data.items():\n",
    "    # Iterate over policies\n",
    "    for policy, df in policies_dict.items():\n",
    "        # Skip the custom_key\n",
    "        if policy == 'min_avg_jct':\n",
    "            continue\n",
    "        # Add a MultiIndex level with trace and policy names\n",
    "        df.index = pd.MultiIndex.from_tuples([(trace, policy)] * len(df), names=['trace', 'policy'])\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "    # Append the custom key to the list\n",
    "    custom_keys.append((trace, policies_dict['min_avg_jct']))\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs)\n",
    "\n",
    "# Create a DataFrame for custom keys\n",
    "custom_keys_df = pd.DataFrame(custom_keys, columns=['trace', 'min_avg_jct'])\n",
    "\n",
    "# Set the 'trace' column as the index\n",
    "custom_keys_df.set_index('trace', inplace=True)\n",
    "\n",
    "# Now 'combined_df' is a single DataFrame with MultiIndex where the first level corresponds to trace names and the second level corresponds to policy names\n",
    "# 'custom_keys_df' is a DataFrame containing custom keys indexed by trace names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e04d8-9f17-485b-b4eb-08c3344adad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizing data in the format accepted by plotting utils\n",
    "# fig7a\n",
    "\n",
    "data = {\"traces\": list(pd_data.keys()), \"data\": {}}\n",
    "\n",
    "for policy in all_policies:\n",
    "    data[\"data\"][policy] = []\n",
    "    for trace in all_traces:\n",
    "        df = combined_df.loc[(trace, policy)]\n",
    "        data[\"data\"][policy].append(df['jct'].mean()/custom_keys_df.loc[trace, 'min_avg_jct'])\n",
    "\n",
    "ax = plot_fig7a(data=data)\n",
    "ax.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682fcbf-edd9-4c49-9412-8bf43645309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizing data in the format accepted by plotting utils\n",
    "# fig7a\n",
    "\n",
    "avg_error_data = {\"traces\": list(pd_data.keys()), \"data\": {}}\n",
    "p99_error_data = {\"traces\": list(pd_data.keys()), \"data\": {}}\n",
    "for policy in all_policies:\n",
    "    avg_error_data[\"data\"][policy] = []\n",
    "    p99_error_data[\"data\"][policy] = []\n",
    "    for trace in all_traces:\n",
    "        df = combined_df.loc[(trace, policy)]\n",
    "        valid_prediction = (df['estimated_end_time'] != -1) & (df['estimated_start_time'] != -1)\n",
    "\n",
    "        filtered_df = df[valid_prediction]\n",
    "\n",
    "        pred_jct = filtered_df['estimated_end_time'] - filtered_df['submit_time']\n",
    "        jct = filtered_df['end_time'] - filtered_df['submit_time']\n",
    "        error = 100.0 * (pred_jct - jct).abs() / pred_jct\n",
    "                \n",
    "        avg_error_data[\"data\"][policy].append(filtered_df['error'].mean())\n",
    "        p99_error_data[\"data\"][policy].append(filtered_df['error'].quantile(0.99))\n",
    "\n",
    "ax = plot_fig7b(data1=avg_error_data,data2=p99_error_data)\n",
    "ax.figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
